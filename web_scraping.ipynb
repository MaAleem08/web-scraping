{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gW-R46Rz8B2"
      },
      "source": [
        "SCRAPING WEBPAGE THAT SELLS BOOKS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv"
      ],
      "metadata": {
        "id": "mbecQ5fcRgDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8rKnghEpfxWB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "r = requests.get(\"https://books.toscrape.com/catalogue/page-2.html\")\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(r.content,'html5lib')\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgimMfXJha_l"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "table = soup.find('ol',attrs = {'class':'row'})\n",
        "\n",
        "books = []\n",
        "\n",
        "for i in table.findAll('li',attrs = {'class':'col-xs-6 col-sm-4 col-md-3 col-lg-3'}):\n",
        "  book = {}\n",
        "  book['Title'] = i.img['alt']\n",
        "  book['image'] = i.img['src']\n",
        "  book['book link'] = i.a['href']\n",
        "  book['star rating'] = i.p['class'][1]\n",
        "  book['price in £'] = i.find('p',attrs = {'class':\"price_color\"}).text.strip('£')\n",
        "  book['availability'] = ''\n",
        "  book['availability'] = 'available' if i.find('p',attrs = {'class':\"instock availability\"}).text[19:27] == 'In stock' else 'out of stock'\n",
        "  books.append(book)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm9qJw0EPI1z"
      },
      "outputs": [],
      "source": [
        "filename = 'book scaraping.csv'\n",
        "with open(filename, 'a', newline='') as f:   # we wrote 'a' to append nwe lines \n",
        "    w = csv.DictWriter(f,['Title','image','book link','star rating','price in £','availability'])\n",
        "    w.writeheader()\n",
        "    for k in books:\n",
        "      w.writerow(k)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_s2ZK9hRiSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2hJRvcFRqk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8sRFzT5-Rq2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVIGTJEB_8LU"
      },
      "source": [
        "SCRAPING QUOTES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muVAi3pP_7Jf"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "r = requests.get('http://quotes.toscrape.com/page/2/')\n",
        "soup = BeautifulSoup(r.content,'html5lib')\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf4GFLbaATcl"
      },
      "outputs": [],
      "source": [
        "table = soup.findAll('div',attrs = {'class':'quote','itemtype':'http://schema.org/CreativeWork'})\n",
        "\n",
        "sayings = []\n",
        "for i in table :\n",
        "  sayng = {}\n",
        "  sayng['quote'] = i.find('span',attrs = {'class':\"text\"}).text\n",
        "  sayng['Author'] = i.a['href'].rsplit('/')[2]\n",
        "  sayng['tags'] = i.meta['content']\n",
        "  sayings.append(sayng)\n",
        "\n",
        "with open('Quotes to Scrape.csv','a',newline='')as f:\n",
        "  w = csv.DictWriter(f,['quote','Author','tags'])\n",
        "  w.writeheader()\n",
        "  for i in sayings:\n",
        "    w.writerow(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('Quotes to Scrape.csv')"
      ],
      "metadata": {
        "id": "rM2QLFNRRwLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}